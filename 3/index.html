<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Project 2 — Fun with Filters and Frequencies (CS180)</title>
  <style>
    body { font-family: "Segoe UI", Arial, sans-serif; margin: 30px; line-height: 1.6; background:#fdfdfd; color:#333; }
    h1 { text-align: center; margin-bottom: 25px; font-size: 2.2em; color:#222; letter-spacing: .5px; }
    h2 { margin-top: 36px; padding-left: 12px; font-size: 1.5em; font-weight: 600; color:#005fa3;
         border-left: 6px solid #007acc; background: linear-gradient(to right, #f0f8ff, #ffffff);
         border-radius: 4px; padding-top: 6px; padding-bottom: 6px; }
    h3 { margin: 6px 0 2px; }
    small { display:block; font-size:.85em; color:#555; margin-top: 2px; }
    .row { display:flex; flex-wrap: wrap; align-items: center; margin: 8px 0 18px; }
    .cap { min-width: 260px; max-width: 360px; }
    img { max-width: 320px; border: 2px solid #ddd; border-radius: 8px; margin: 10px; box-shadow: 2px 2px 6px rgba(0,0,0,0.15); transition: transform .2s ease; }
    img:hover { transform: scale(1.02); }
    .back a { display:inline-block; margin-top: 28px; text-decoration:none; color:#fff; background:#007acc; padding: 8px 14px; border-radius:6px; font-weight:500; }
    .back a:hover { background:#005fa3; }
    code { background:#f3f6fa; padding: 1px 4px; border-radius:4px; }
  </style>
</head>
<body>
  <h1>Project 2 — Fun with Filters and Frequencies (CS180)</h1>

  <h2>Overview</h2>
  <p>
    This project explores how linear filters and frequency representations shape images.
    I first implement convolution from scratch and finite-difference edges. Then I use
    Gaussian/DoG filters to denoise gradients. In Part 2, I apply unsharp masking to
    enhance high frequencies, build hybrid images that mix low/high bands, and finish
    with multiresolution blending using Gaussian/Laplacian stacks.
  </p>

  <!-- ===================== Part 1.1 ===================== -->
  <h2 id="part1-1">Part 1.1: Convolutions from Scratch</h2>
  <p>
    I implemented convolution with four loops, then optimized to two loops with NumPy slicing,
    and compared outputs to <code>scipy.signal.convolve2d</code>. Zero padding is used so sizes
    match. The single panel below summarizes the grayscale input, 9×9 box-filtered result,
    and finite differences in x/y for my selfie.
  </p>
  <div class="row">
    <div class="cap">
      <h3>Part 1.1 Summary</h3>
      <small>Gray • Box 9×9 • Dx • Dy</small>
    </div>
    <img src="./media/part1_1_summary.png" alt="Part 1.1 summary panel">
  </div>

  <!-- ===================== Part 1.2 ===================== -->
  <h2 id="part1-2">Part 1.2: Finite Difference Operator</h2>
  <p>
    I computed partial derivatives (Dx, Dy) on the Cameraman image with
    <code>convolve2d</code>, then formed gradient magnitude and thresholded to get an
    edge map. Lower thresholds capture more detail but increase noise, while higher
    thresholds suppress both. I chose a mid value to keep dominant structures visible.
  </p>
  <div class="row">
    <div class="cap"><h3>Finite Differences</h3><small>Cameraman — Dx, Dy, |∇|, edges</small></div>
    <img src="./media/part1_2_dx.png" alt="Dx">
    <img src="./media/part1_2_dy.png" alt="Dy">
    <img src="./media/part1_2_mag.png" alt="Gradient magnitude">
    <img src="./media/part1_2_edges.png" alt="Binarized edges">
  </div>

  <!-- ===================== Part 1.3 ===================== -->
  <h2 id="part1-3">Part 1.3: Derivative of Gaussian (DoG)</h2>
  <p>
    I smoothed the image with a Gaussian and re-ran the edge pipeline, which reduced
    speckle noise and isolated coherent contours. I also pre-convolved Dx/Dy with the
    Gaussian to form DoG filters that match the two-step result. The DoG approach is
    efficient and yields similar edges with less noise.
  </p>
  <div class="row">
    <div class="cap"><h3>DoG Filters & Results</h3><small>DoG<sub>x</sub>, DoG<sub>y</sub>, blurred, edges</small></div>
    <img src="./media/part1_3_dogx.png" alt="DoGx">
    <img src="./media/part1_3_dogy.png" alt="DoGy">
    <img src="./media/part1_3_blurred.png" alt="Blurred">
    <img src="./media/part1_3_edges.png" alt="Edges (DoG)">
  </div>

  <!-- ===================== Part 2.1 ===================== -->
  <h2 id="part2-1">Part 2.1: Image “Sharpening” (Unsharp Mask)</h2>
  <p>
    Unsharp masking adds a scaled high-frequency residual <code>(I − G∗I)</code> back to
    the image to increase perceived sharpness. I show Taj at different amounts, a blurred
    sharp image re-sharpened, and the high-frequency visualization. Too much gain amplifies
    noise and halos; moderate values preserve detail naturally.
  </p>
  <div class="row">
    <div class="cap"><h3>Taj — Sharpening</h3><small>Original, a=0.5, a=1.0, a=1.5</small></div>
    <img src="./media/part2_1_taj_orig.png" alt="Taj original">
    <img src="./media/part2_1_taj_a05.png" alt="Taj a=0.5">
    <img src="./media/part2_1_taj_a10.png" alt="Taj a=1.0">
    <img src="./media/part2_1_taj_a15.png" alt="Taj a=1.5">
  </div>
  <div class="row">
    <div class="cap"><h3>Sharpening Analysis</h3><small>Blurred, high-freq (viz), re-sharpened</small></div>
    <img src="./media/part2_1_blurred.png" alt="Blurred">
    <img src="./media/part2_1_highfreq.png" alt="High frequency viz">
    <img src="./media/part2_1_sharpened.png" alt="Re-sharpened">
  </div>

  <!-- ===================== Part 2.2 ===================== -->
  <h2 id="part2-2">Part 2.2: Hybrid Images</h2>
  <p>
    A hybrid image sums a low-pass version of one image with a high-pass of another.
    Up close, the high frequencies dominate; at a distance, the low frequencies remain.
    I aligned pairs with clicked keypoints, tuned Gaussian sigmas per band, and visualized
    FFT log-magnitudes for my favorite hybrid.
  </p>
  <div class="row">
    <div class="cap"><h3>Derek + Nutmeg (Process)</h3><small>Inputs, filtered bands, FFTs, final</small></div>
    <img src="./media/part2_2_dn_inputs.png" alt="Derek/Nutmeg inputs">
    <img src="./media/part2_2_dn_filtered.png" alt="Low/High bands">
    <img src="./media/part2_2_dn_ffts.png" alt="FFTs">
    <img src="./media/part2_2_dn_hybrid.png" alt="Hybrid">
  </div>
  <div class="row">
    <div class="cap"><h3>Hybrid #2</h3><small>Inputs and final</small></div>
    <img src="./media/part2_2_h2_inputs.png" alt="Hybrid 2 inputs">
    <img src="./media/part2_2_h2_out.png" alt="Hybrid 2 output">
  </div>
  <div class="row">
    <div class="cap"><h3>Hybrid #3</h3><small>Inputs and final</small></div>
    <img src="./media/part2_2_h3_inputs.png" alt="Hybrid 3 inputs">
    <img src="./media/part2_2_h3_out.png" alt="Hybrid 3 output">
  </div>

  <!-- ===================== Part 2.3 ===================== -->
  <h2 id="part2-3">Part 2.3: Gaussian & Laplacian Stacks</h2>
  <p>
    I built stacks without downsampling by repeatedly blurring (Gaussian) and differencing
    adjacent levels (Laplacian). Applying this to Apple/Orange reproduces Szelski Fig. 3.42:
    level-wise contributions at high/medium/low frequencies, masked bases, and the final
    multi-band reconstruction. The stacks are also reused for blending.
  </p>
  <div class="row">
    <div class="cap"><h3>Apple/Orange — Fig. 3.42</h3><small>(a–l) reconstruction panels</small></div>
    <img src="./media/part2_3_fig342.png" alt="Figure 3.42 panels">
  </div>

  <!-- ===================== Part 2.4 ===================== -->
  <h2 id="part2-4">Part 2.4: Multiresolution Blending (Oraple)</h2>
  <p>
    I blend images with a smoothed mask at each level: multiply the mask’s Gaussian stack
    with corresponding Laplacian levels and sum with a blended base. Vertical/horizontal
    masks create clean halves, while irregular masks produce natural seams around shapes.
    I include Apple/Orange and two custom pairs.
  </p>
  <div class="row">
    <div class="cap"><h3>Oraple — Vertical/Horizontal/Irregular</h3><small>Inputs, masks, blends</small></div>
    <img src="./media/part2_4_apple.png" alt="Apple/Orange blend">
    <img src="./media/part2_4_morning_night.png" alt="Morning/Night blend">
    <img src="./media/part2_4_mountain_waterfall.png" alt="Mountain/Waterfall blend">
  </div>

  <h2>Reflection</h2>
  <p>
    The main insight was how frequency bands control perception: sharpening and hybrids
    rely on boosting or isolating bands, while multiresolution blending hides seams by
    smoothing masks per level. Good alignment matters a lot for hybrids. Choosing sigmas
    and mask shapes gives strong creative control.
  </p>

  <p class="back"><a href="../index.html">⬅ Back to main page</a></p>
</body>
</html>
