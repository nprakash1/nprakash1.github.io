<!DOCTYPE html>
<html>
<head>
  <title>Project 2 — Fun with Filters and Frequencies</title>
  <style>
    body { font-family: "Segoe UI", Arial, sans-serif; margin: 30px; line-height: 1.6; background: #fdfdfd; color: #333; }
    h1 { text-align: center; margin-bottom: 25px; font-size: 2.2em; color: #222; letter-spacing: 1px; }
    h2 { margin-top: 40px; padding-left: 12px; font-size: 1.5em; font-weight: 600; color: #005fa3;
         border-left: 6px solid #007acc; background: linear-gradient(to right, #f0f8ff, #ffffff);
         border-radius: 4px; padding-top: 6px; padding-bottom: 6px; }
    h3 { margin: 14px 0 6px; }
    small { display:block; font-size: .85em; color:#555; margin-top: 4px; }
    img { max-width: 300px; border: 2px solid #ddd; border-radius: 8px; margin: 12px; box-shadow: 2px 2px 6px rgba(0,0,0,0.15); transition: transform 0.2s ease; }
    img:hover { transform: scale(1.02); }
    .wide { max-width: 720px; }
    .row { display:flex; flex-wrap: wrap; align-items: center; }
    .cap { min-width: 260px; }
    .back a { display:inline-block; margin-top:30px; text-decoration:none; color:#fff; background:#007acc; padding:8px 14px; border-radius:6px; font-weight:500; }
    .back a:hover { background:#005fa3; }
  </style>
</head>
<body>
  <h1>CS180 Project 2: Fun with Filters and Frequencies</h1>

  <h2>Overview</h2>
  <p>
    This project explores 2D convolution, edge detection, frequency filtering, hybrid images, and multi-resolution blending.
    I implement core filters from scratch, visualize Gaussian/Laplacian stacks, and blend images using smooth masks.
  </p>

  <h2>Part 1.1: Convolutions from Scratch</h2>
  <p>
    I implemented convolution with four loops and two loops (zero padding), then compared against <code>scipy.signal.convolve2d</code>. Below is a summary collage showing the original,
    box-filtered output, and comparisons to SciPy. 
  </p>
  <p><em>Runtime note:</em> Finite-difference filters (e.g., 1×2 / 2×1) are much faster than a 9×9 box filter because they do O(1) work per pixel vs. ~81 operations per pixel.</p>
  <div class="row">
    <div class="cap">
      <h3>Convolution summary</h3>
      <small>Four-loop vs two-loop vs SciPy comparisons</small>
    </div>
    <img class="wide" src="./media/part1_1_summary.png" alt="Part 1.1 summary collage">
  </div>
  <div class="row">
    <div class="cap">
      <h3>Finite difference result</h3>
      <small>Dx/Dy responses and combined view</small>
    </div>
    <img class="wide" src="./media/part1_1_finite_diff.png" alt="Part 1.1 finite difference output">
  </div>

  <h2>Part 1.2: Finite Difference Operator</h2>
  <p>
    I convolved the image with D<sub>x</sub> and D<sub>y</sub>, computed gradient magnitude, and binarized it with a threshold to get an edge map.
    The main trade-off is between removing noise and missing faint edges; I tuned a threshold to balance both.
  </p>
  <div class="row"><div class="cap"><h3>Cameraman — Dx/Dy/Edges</h3></div><img src="./media/part1_2_edges.png" alt="part 1.2"></div>

  <h2>Part 1.3: Derivative of Gaussian (DoG)</h2>
  <p>
    I first smoothed with a Gaussian, then took derivatives; I also built DoG filters by convolving the Gaussian with D<sub>x</sub>, D<sub>y</sub>.
    The DoG result matches “blur→diff” but is cleaner and less noisy due to smoothing.
  </p>
  <div class="row"><div class="cap"><h3>DoG filters + results</h3></div><img src="./media/part1_3_dog.png" alt="part 1.3"></div>

  <h2>Part 2.1: Image Sharpening (Unsharp Mask)</h2>
  <p>
    I sharpen by adding a scaled high-frequency component: <code>sharp = img + a·(img − G*img)</code>. I show the blurred image, extracted highs, and sharpened outputs for different amounts.
    I also blur a sharp image and try to recover it; sharpening boosts edges but cannot restore lost detail perfectly.
  </p>
  <div class="row"><div class="cap"><h3>Taj — blur/highs/sharpened</h3></div><img src="./media/part2_1_taj.png" alt="part 2.1 taj"></div>
  <div class="row"><div class="cap"><h3>Custom — blur/highs/sharpened</h3></div><img src="./media/part2_1_custom.png" alt="part 2.1 custom"></div>

  <h2>Part 2.2: Hybrid Images</h2>
  <p>
    I align pairs, low-pass one image and high-pass the other, then add. At close range you see high frequencies; from far away, low frequencies dominate.
    I visualize FFT log-magnitudes to show how filtering redistributes energy.
  </p>
  <div class="row"><div class="cap"><h3>Derek + Nutmeg — pipeline</h3></div><img src="./media/part2_2_dn_pipeline.png" alt="DN pipeline"></div>
  <div class="row"><div class="cap"><h3>Hybrid results</h3></div><img src="./media/part2_2_hybrids.png" alt="hybrids"></div>

  <h2>Part 2.3: Gaussian & Laplacian Stacks</h2>
  <p>
    I build stacks without downsampling: repeated Gaussian smoothing for the Gaussian stack and differences between levels for the Laplacian stack.
    The Laplacian bands isolate structures from fine to coarse, matching Szelski Fig. 3.42 behavior.
  </p>
  <div class="row"><div class="cap"><h3>Apple/Orange — stacks and levels</h3></div><img src="./media/part2_3_oraple_stacks.png" alt="stacks"></div>

  <h2>Part 2.4: Multiresolution Blending</h2>
  <p>
    I blur a mask into a Gaussian stack and combine the two images’ Laplacian stacks level-wise, then add the base level. This yields a smooth seam.
    I show vertical, horizontal, and irregular (circular) masks, plus two creative blends.
  </p>
  <div class="row"><div class="cap"><h3>Oraple blends (v/h/circle)</h3></div><img src="./media/part2_4_oraple_blends.png" alt="oraple blends"></div>
  <div class="row"><div class="cap"><h3>Custom blends</h3></div><img src="./media/part2_4_custom.png" alt="custom blends"></div>

  <h2>Most Important Lesson</h2>
  <p>
    Frequency-domain thinking makes many “visual tricks” straightforward: once you can isolate bands cleanly and combine them with masks across scales, alignment and masking choices matter more than any single filter.
  </p>

  <p class="back"><a href="../index.html">⬅ Back to main page</a></p>
</body>
</html>
